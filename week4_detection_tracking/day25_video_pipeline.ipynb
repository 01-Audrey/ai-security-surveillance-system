{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc234ea-9713-41c3-b7d9-5ec0cd1daf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "==================================================\n",
    "ML LEARNING JOURNEY - DAY 25\n",
    "==================================================\n",
    "Week: 4 of 24\n",
    "Day: 25 of 168\n",
    "Date: November 20, 2025\n",
    "Topic: Video Processing Pipeline\n",
    "Overall Progress: 14.9%\n",
    "\n",
    "Week 4: Detection & Tracking Foundation\n",
    "‚úÖ Day 22: Project Planning & Architecture (COMPLETED)\n",
    "‚úÖ Day 23: Multi-Object Tracking (DeepSORT) (COMPLETED)\n",
    "‚úÖ Day 24: Tracking Optimization (COMPLETED)\n",
    "üîÑ Day 25: Video Processing Pipeline (TODAY!)\n",
    "‚¨ú Day 26: Testing & Performance\n",
    "‚¨ú Day 27: Code Cleanup & Modularization\n",
    "‚¨ú Day 28: Week 4 Review\n",
    "\n",
    "Progress: 57% (4/7 days)\n",
    "\n",
    "==================================================\n",
    "üéØ Week 4 Project: Security System - Detection & Tracking\n",
    "- Build production-ready video processing pipeline\n",
    "- Handle multiple input sources (files, webcam, RTSP)\n",
    "- Process videos efficiently at scale\n",
    "- Export results in multiple formats\n",
    "- Optimize for sustained 30 FPS performance\n",
    "\n",
    "üéØ Today's Learning Objectives:\n",
    "1. Build robust video input/output handling\n",
    "2. Implement multi-threaded video processing\n",
    "3. Handle multiple video sources simultaneously\n",
    "4. Create frame queue management system\n",
    "5. Implement batch video processing\n",
    "6. Export annotated videos and detection logs\n",
    "7. Optimize memory and performance\n",
    "8. Handle errors gracefully\n",
    "\n",
    "üìö Today's Structure:\n",
    "   Part 1 (2h): Video I/O Fundamentals\n",
    "   Part 2 (2h): Multi-Source Processing\n",
    "   Part 3 (1.5h): Batch Processing & Export\n",
    "   Part 4 (1h): Testing & Summary\n",
    "\n",
    "üéØ SUCCESS CRITERIA:\n",
    "   ‚úÖ Process video files (MP4, AVI, MOV)\n",
    "   ‚úÖ Handle webcam and RTSP streams\n",
    "   ‚úÖ Multi-threaded processing working\n",
    "   ‚úÖ Batch process multiple videos\n",
    "   ‚úÖ Export annotated videos\n",
    "   ‚úÖ Export detection logs (CSV, JSON)\n",
    "   ‚úÖ Sustained 30 FPS on video files\n",
    "   ‚úÖ Memory-efficient processing\n",
    "==================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d525e48-69df-4310-9e96-bbc3c46edfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Installing required libraries...\n",
      "‚è±Ô∏è  This should be quick (most already installed)...\n",
      "\n",
      "Checking ultralytics...\n",
      "Checking deep-sort-realtime...\n",
      "Checking opencv-python...\n",
      "Checking numpy...\n",
      "Checking pandas...\n",
      "Checking matplotlib...\n",
      "Checking tqdm...\n",
      "Checking pillow...\n",
      "\n",
      "‚úÖ All libraries ready!\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üìö IMPORTING LIBRARIES\n",
      "================================================================================\n",
      "\n",
      "‚úÖ All libraries imported successfully!\n",
      "\n",
      "üìä Library versions:\n",
      "   ‚Ä¢ OpenCV: 4.12.0\n",
      "   ‚Ä¢ NumPy: 2.2.6\n",
      "   ‚Ä¢ Pandas: 2.3.2\n",
      "   ‚Ä¢ Ultralytics: Installed ‚úì\n",
      "   ‚Ä¢ DeepSORT: Installed ‚úì\n",
      "   ‚Ä¢ tqdm: Installed ‚úì\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# INSTALL REQUIRED LIBRARIES\n",
    "# ==================================================\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"üì¶ Installing required libraries...\")\n",
    "print(\"‚è±Ô∏è  This should be quick (most already installed)...\\n\")\n",
    "\n",
    "packages = [\n",
    "    'ultralytics',\n",
    "    'deep-sort-realtime',\n",
    "    'opencv-python',\n",
    "    'numpy',\n",
    "    'pandas',\n",
    "    'matplotlib',\n",
    "    'tqdm',  # Progress bars\n",
    "    'pillow'\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    print(f\"Checking {package}...\")\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', package, '-q'])\n",
    "\n",
    "print(\"\\n‚úÖ All libraries ready!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# ==================================================\n",
    "# IMPORT LIBRARIES\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìö IMPORTING LIBRARIES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Standard libraries\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, deque\n",
    "from datetime import datetime\n",
    "import threading\n",
    "from queue import Queue\n",
    "\n",
    "# Data science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Computer vision\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Deep learning\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Tracking\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# Progress bars\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"\\n‚úÖ All libraries imported successfully!\")\n",
    "print(\"\\nüìä Library versions:\")\n",
    "print(f\"   ‚Ä¢ OpenCV: {cv2.__version__}\")\n",
    "print(f\"   ‚Ä¢ NumPy: {np.__version__}\")\n",
    "print(f\"   ‚Ä¢ Pandas: {pd.__version__}\")\n",
    "print(\"   ‚Ä¢ Ultralytics: Installed ‚úì\")\n",
    "print(\"   ‚Ä¢ DeepSORT: Installed ‚úì\")\n",
    "print(\"   ‚Ä¢ tqdm: Installed ‚úì\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d8051ab-d1c8-489e-9f4e-816a3f2be3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìö PART 1: VIDEO I/O FUNDAMENTALS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìö PART 1: VIDEO I/O FUNDAMENTALS\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bcbce75-32e8-471b-ae44-03385a9e5ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXERCISE 1.1: Understanding Video Input Sources\n",
      "================================================================================\n",
      "\n",
      "üìä VIDEO SOURCE COMPARISON:\n",
      "\n",
      "Source      | Speed  | Seek | Quality | Use Case\n",
      "------------|--------|------|---------|------------------\n",
      "Video File  | Medium | Yes  | High    | Batch processing\n",
      "Webcam      | Fast   | No   | Medium  | Development/testing\n",
      "RTSP Stream | Slow   | No   | High    | Production/live\n",
      "Images      | Slow   | Yes  | Highest | Research/quality\n",
      "\n",
      "Recommendation for Security System:\n",
      "- Development: Webcam (interactive testing)\n",
      "- Testing: Video files (repeatable)\n",
      "- Production: RTSP streams (live monitoring)\n",
      "- Analysis: Video files (post-processing)\n",
      "\n",
      "\n",
      "‚úÖ Exercise 1.1 Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# EXERCISE 1.1: UNDERSTAND VIDEO INPUT SOURCES\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXERCISE 1.1: Understanding Video Input Sources\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\"\"\"\n",
    "üìñ THEORY: Video Input Sources and Formats\n",
    "\n",
    "Types of Video Sources:\n",
    "1. Video Files (Recorded)\n",
    "2. Webcam (Live)\n",
    "3. RTSP Streams (Network cameras)\n",
    "4. Image Sequences\n",
    "5. Screen Capture\n",
    "\n",
    "==================================================\n",
    "\n",
    "1. VIDEO FILES:\n",
    "\n",
    "Common Formats:\n",
    "- MP4 (H.264/H.265) - Most common, good compression\n",
    "- AVI (Various codecs) - Older, larger files\n",
    "- MOV (QuickTime) - Apple format\n",
    "- MKV (Matroska) - Open format, flexible\n",
    "- WMV (Windows Media) - Microsoft format\n",
    "\n",
    "OpenCV Support:\n",
    "- cv2.VideoCapture(filename) - Opens video file\n",
    "- Codecs handled by FFmpeg backend\n",
    "- Most formats supported out-of-box\n",
    "\n",
    "Properties:\n",
    "- Total frames: cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "- FPS: cap.get(cv2.CAP_PROP_FPS)\n",
    "- Width: cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "- Height: cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "- Codec: cap.get(cv2.CAP_PROP_FOURCC)\n",
    "\n",
    "Advantages:\n",
    "‚úì Repeatable (same content every time)\n",
    "‚úì No time pressure (can process slower)\n",
    "‚úì Easy to share and archive\n",
    "‚úì Can seek to specific frames\n",
    "\n",
    "Challenges:\n",
    "‚úó Large file sizes\n",
    "‚úó Decoding overhead\n",
    "‚úó May have variable frame rates\n",
    "‚úó Codec compatibility issues\n",
    "\n",
    "==================================================\n",
    "\n",
    "2. WEBCAM:\n",
    "\n",
    "Access:\n",
    "- cv2.VideoCapture(0) - Default webcam\n",
    "- cv2.VideoCapture(1) - Second camera\n",
    "- cv2.VideoCapture(device_index)\n",
    "\n",
    "Properties:\n",
    "- Live stream (real-time)\n",
    "- Fixed FPS (usually 30)\n",
    "- Variable resolution (depends on camera)\n",
    "\n",
    "Advantages:\n",
    "‚úì Real-time testing\n",
    "‚úì Interactive development\n",
    "‚úì No file I/O overhead\n",
    "\n",
    "Challenges:\n",
    "‚úó Must process in real-time\n",
    "‚úó Cannot seek/rewind\n",
    "‚úó Hardware dependent\n",
    "‚úó May have latency\n",
    "\n",
    "==================================================\n",
    "\n",
    "3. RTSP STREAMS (IP Cameras):\n",
    "\n",
    "Access:\n",
    "- cv2.VideoCapture('rtsp://user:pass@ip:port/path')\n",
    "- Example: 'rtsp://admin:password@192.168.1.100:554/stream1'\n",
    "\n",
    "Properties:\n",
    "- Network-based\n",
    "- Real-time streaming\n",
    "- Multiple clients can connect\n",
    "- Professional security cameras\n",
    "\n",
    "Advantages:\n",
    "‚úì Remote access\n",
    "‚úì Multiple camera support\n",
    "‚úì Professional quality\n",
    "‚úì Built-in recording\n",
    "\n",
    "Challenges:\n",
    "‚úó Network latency\n",
    "‚úó Connection drops\n",
    "‚úó Buffering issues\n",
    "‚úó Authentication required\n",
    "‚úó Bandwidth considerations\n",
    "\n",
    "==================================================\n",
    "\n",
    "4. IMAGE SEQUENCES:\n",
    "\n",
    "Access:\n",
    "- cv2.VideoCapture('frame_%04d.jpg')\n",
    "- Reads: frame_0001.jpg, frame_0002.jpg, ...\n",
    "\n",
    "Use Cases:\n",
    "- High-quality processing\n",
    "- Frame-by-frame analysis\n",
    "- Scientific imaging\n",
    "- Post-production work\n",
    "\n",
    "Advantages:\n",
    "‚úì Lossless quality\n",
    "‚úì Easy to edit individual frames\n",
    "‚úì No codec issues\n",
    "‚úì Flexible processing\n",
    "\n",
    "Challenges:\n",
    "‚úó Many files to manage\n",
    "‚úó Large disk space\n",
    "‚úó Slower I/O\n",
    "‚úó Manual frame rate control\n",
    "\n",
    "==================================================\n",
    "\n",
    "OPENCV VIDEOCAPTURE API:\n",
    "\n",
    "Opening:\n",
    "cap = cv2.VideoCapture(source)\n",
    "\n",
    "Properties:\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "Reading:\n",
    "ret, frame = cap.read()\n",
    "# ret: True if frame read successfully\n",
    "# frame: numpy array (height, width, 3) BGR format\n",
    "\n",
    "Seeking:\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "# Jump to specific frame (only for files)\n",
    "\n",
    "Releasing:\n",
    "cap.release()\n",
    "# Always release when done!\n",
    "\n",
    "==================================================\n",
    "\n",
    "HANDLING DIFFERENT SOURCES:\n",
    "\n",
    "File:\n",
    "cap = cv2.VideoCapture('video.mp4')\n",
    "# Can seek, get total frames, process at any speed\n",
    "\n",
    "Webcam:\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Real-time only, no seeking, must keep up with FPS\n",
    "\n",
    "RTSP:\n",
    "cap = cv2.VideoCapture('rtsp://...')\n",
    "# Real-time, network latency, may drop frames\n",
    "\n",
    "Image Sequence:\n",
    "cap = cv2.VideoCapture('frame_%04d.jpg')\n",
    "# Like file, but separate images\n",
    "\n",
    "==================================================\n",
    "\n",
    "BEST PRACTICES:\n",
    "\n",
    "1. Always check if opened:\n",
    "   if not cap.isOpened():\n",
    "       print(\"Error opening video\")\n",
    "\n",
    "2. Handle read failures:\n",
    "   ret, frame = cap.read()\n",
    "   if not ret:\n",
    "       break  # End of video or error\n",
    "\n",
    "3. Get properties first:\n",
    "   fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "   width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "4. Release when done:\n",
    "   cap.release()\n",
    "   cv2.destroyAllWindows()\n",
    "\n",
    "5. For production:\n",
    "   - Implement retry logic (RTSP)\n",
    "   - Buffer frames (smooth playback)\n",
    "   - Handle codec errors\n",
    "   - Log failures\n",
    "\n",
    "==================================================\n",
    "\n",
    "PERFORMANCE CONSIDERATIONS:\n",
    "\n",
    "Decoding Speed:\n",
    "- H.264: Fast, widely supported\n",
    "- H.265: Slower, better compression\n",
    "- Uncompressed: Fastest but huge\n",
    "\n",
    "Resolution:\n",
    "- 640x480: Fast (VGA)\n",
    "- 1280x720: Medium (HD)\n",
    "- 1920x1080: Slow (Full HD)\n",
    "- 3840x2160: Very slow (4K)\n",
    "\n",
    "Frame Rate:\n",
    "- 15 FPS: Acceptable for security\n",
    "- 30 FPS: Standard\n",
    "- 60 FPS: Requires double processing\n",
    "\n",
    "Network:\n",
    "- Local: Fast, reliable\n",
    "- RTSP: Variable, depends on network\n",
    "- Cloud: Slow, high latency\n",
    "\"\"\"\n",
    "\n",
    "print(\"\"\"\n",
    "üìä VIDEO SOURCE COMPARISON:\n",
    "\n",
    "Source      | Speed  | Seek | Quality | Use Case\n",
    "------------|--------|------|---------|------------------\n",
    "Video File  | Medium | Yes  | High    | Batch processing\n",
    "Webcam      | Fast   | No   | Medium  | Development/testing\n",
    "RTSP Stream | Slow   | No   | High    | Production/live\n",
    "Images      | Slow   | Yes  | Highest | Research/quality\n",
    "\n",
    "Recommendation for Security System:\n",
    "- Development: Webcam (interactive testing)\n",
    "- Testing: Video files (repeatable)\n",
    "- Production: RTSP streams (live monitoring)\n",
    "- Analysis: Video files (post-processing)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n‚úÖ Exercise 1.1 Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62882438-5817-4692-aafe-d5c90fccd8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXERCISE 1.2: Build Robust Video Input Class\n",
      "================================================================================\n",
      "‚úÖ Class created: VideoInput\n",
      "\n",
      "üìä Features:\n",
      "   ‚Ä¢ Auto-detect source type (file/webcam/stream)\n",
      "   ‚Ä¢ Retry logic for robust opening\n",
      "   ‚Ä¢ Get video properties (width, height, fps)\n",
      "   ‚Ä¢ Progress tracking (for files)\n",
      "   ‚Ä¢ Context manager support (with statement)\n",
      "   ‚Ä¢ Proper resource cleanup\n",
      "\n",
      "üß™ Testing VideoInput class...\n",
      "\n",
      "============================================================\n",
      "Testing source: 0\n",
      "============================================================\n",
      "‚ö†Ô∏è  Attempt 1 failed, retrying...\n",
      "‚ö†Ô∏è  Attempt 2 failed, retrying...\n",
      "\n",
      "‚ö†Ô∏è  Test skipped for 0: ‚ùå Failed to open video source: 0\n",
      "‚úÖ Released video source: 0\n",
      "\n",
      "‚úÖ Exercise 1.2 Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# EXERCISE 1.2: BUILD VIDEO INPUT CLASS\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXERCISE 1.2: Build Robust Video Input Class\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\"\"\"\n",
    "üìñ THEORY: Video Input Abstraction\n",
    "\n",
    "Why Create a Class?\n",
    "- Unified interface for all sources\n",
    "- Handles errors consistently\n",
    "- Manages resources properly\n",
    "- Adds useful features (retry, buffering)\n",
    "- Easy to extend and maintain\n",
    "\n",
    "Key Features:\n",
    "1. Auto-detect source type\n",
    "2. Get video properties\n",
    "3. Read frames reliably\n",
    "4. Handle errors gracefully\n",
    "5. Release resources properly\n",
    "6. Support context manager (with statement)\n",
    "\"\"\"\n",
    "\n",
    "class VideoInput:\n",
    "    \"\"\"\n",
    "    Robust video input handler for multiple sources\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, source, retry_count=3, buffer_size=1):\n",
    "        \"\"\"\n",
    "        Initialize video input\n",
    "        \n",
    "        Args:\n",
    "            source: Video source (file path, camera index, RTSP URL)\n",
    "            retry_count: Number of retry attempts for opening\n",
    "            buffer_size: Number of frames to buffer\n",
    "        \"\"\"\n",
    "        self.source = source\n",
    "        self.retry_count = retry_count\n",
    "        self.buffer_size = buffer_size\n",
    "        self.cap = None\n",
    "        self.source_type = None\n",
    "        \n",
    "        # Properties\n",
    "        self.width = 0\n",
    "        self.height = 0\n",
    "        self.fps = 0\n",
    "        self.total_frames = 0\n",
    "        self.current_frame = 0\n",
    "        \n",
    "        # Open video source\n",
    "        self._open()\n",
    "    \n",
    "    def _detect_source_type(self):\n",
    "        \"\"\"Detect type of video source\"\"\"\n",
    "        if isinstance(self.source, int):\n",
    "            return \"webcam\"\n",
    "        elif isinstance(self.source, str):\n",
    "            if self.source.startswith('rtsp://') or self.source.startswith('http://'):\n",
    "                return \"stream\"\n",
    "            elif os.path.isfile(self.source):\n",
    "                return \"file\"\n",
    "            elif '%' in self.source:  # Image sequence pattern\n",
    "                return \"images\"\n",
    "        return \"unknown\"\n",
    "    \n",
    "    def _open(self):\n",
    "        \"\"\"Open video source with retry logic\"\"\"\n",
    "        self.source_type = self._detect_source_type()\n",
    "        \n",
    "        for attempt in range(self.retry_count):\n",
    "            try:\n",
    "                self.cap = cv2.VideoCapture(self.source)\n",
    "                \n",
    "                if self.cap.isOpened():\n",
    "                    # Get properties\n",
    "                    self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                    self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                    self.fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "                    \n",
    "                    # Total frames (0 for streams/webcam)\n",
    "                    self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                    if self.total_frames <= 0:\n",
    "                        self.total_frames = None  # Unknown for streams\n",
    "                    \n",
    "                    print(f\"‚úÖ Opened {self.source_type}: {self.source}\")\n",
    "                    print(f\"   Resolution: {self.width}x{self.height}\")\n",
    "                    print(f\"   FPS: {self.fps:.1f}\")\n",
    "                    if self.total_frames:\n",
    "                        print(f\"   Total frames: {self.total_frames}\")\n",
    "                        duration = self.total_frames / self.fps if self.fps > 0 else 0\n",
    "                        print(f\"   Duration: {duration:.1f}s\")\n",
    "                    \n",
    "                    return True\n",
    "                else:\n",
    "                    if attempt < self.retry_count - 1:\n",
    "                        print(f\"‚ö†Ô∏è  Attempt {attempt + 1} failed, retrying...\")\n",
    "                        time.sleep(1)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                if attempt < self.retry_count - 1:\n",
    "                    print(f\"‚ö†Ô∏è  Error on attempt {attempt + 1}: {e}\")\n",
    "                    time.sleep(1)\n",
    "        \n",
    "        raise RuntimeError(f\"‚ùå Failed to open video source: {self.source}\")\n",
    "    \n",
    "    def read(self):\n",
    "        \"\"\"\n",
    "        Read next frame\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (success, frame)\n",
    "        \"\"\"\n",
    "        if self.cap is None or not self.cap.isOpened():\n",
    "            return False, None\n",
    "        \n",
    "        ret, frame = self.cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            self.current_frame += 1\n",
    "        \n",
    "        return ret, frame\n",
    "    \n",
    "    def get_progress(self):\n",
    "        \"\"\"Get progress percentage (for files only)\"\"\"\n",
    "        if self.total_frames is None or self.total_frames == 0:\n",
    "            return None\n",
    "        return (self.current_frame / self.total_frames) * 100\n",
    "    \n",
    "    def seek(self, frame_number):\n",
    "        \"\"\"\n",
    "        Seek to specific frame (files only)\n",
    "        \n",
    "        Args:\n",
    "            frame_number: Frame index to seek to\n",
    "        \"\"\"\n",
    "        if self.source_type not in ['file', 'images']:\n",
    "            print(\"‚ö†Ô∏è  Seeking only supported for video files\")\n",
    "            return False\n",
    "        \n",
    "        self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        self.current_frame = frame_number\n",
    "        return True\n",
    "    \n",
    "    def get_info(self):\n",
    "        \"\"\"Get video information dictionary\"\"\"\n",
    "        return {\n",
    "            'source': str(self.source),\n",
    "            'type': self.source_type,\n",
    "            'width': self.width,\n",
    "            'height': self.height,\n",
    "            'fps': self.fps,\n",
    "            'total_frames': self.total_frames,\n",
    "            'current_frame': self.current_frame\n",
    "        }\n",
    "    \n",
    "    def release(self):\n",
    "        \"\"\"Release video capture\"\"\"\n",
    "        if self.cap is not None:\n",
    "            self.cap.release()\n",
    "            print(f\"‚úÖ Released video source: {self.source}\")\n",
    "    \n",
    "    def __enter__(self):\n",
    "        \"\"\"Context manager entry\"\"\"\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Context manager exit\"\"\"\n",
    "        self.release()\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"Destructor\"\"\"\n",
    "        self.release()\n",
    "\n",
    "print(\"‚úÖ Class created: VideoInput\")\n",
    "print(\"\\nüìä Features:\")\n",
    "print(\"   ‚Ä¢ Auto-detect source type (file/webcam/stream)\")\n",
    "print(\"   ‚Ä¢ Retry logic for robust opening\")\n",
    "print(\"   ‚Ä¢ Get video properties (width, height, fps)\")\n",
    "print(\"   ‚Ä¢ Progress tracking (for files)\")\n",
    "print(\"   ‚Ä¢ Context manager support (with statement)\")\n",
    "print(\"   ‚Ä¢ Proper resource cleanup\")\n",
    "\n",
    "print(\"\\nüß™ Testing VideoInput class...\")\n",
    "\n",
    "# Test with sample video (if exists) or webcam\n",
    "test_sources = [\n",
    "    0,  # Webcam\n",
    "    # 'test_video.mp4',  # Video file (if you have one)\n",
    "]\n",
    "\n",
    "for source in test_sources:\n",
    "    try:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Testing source: {source}\")\n",
    "        print('='*60)\n",
    "        \n",
    "        with VideoInput(source) as video:\n",
    "            info = video.get_info()\n",
    "            print(f\"\\nüìã Video Info:\")\n",
    "            for key, value in info.items():\n",
    "                print(f\"   {key}: {value}\")\n",
    "            \n",
    "            # Read a few frames\n",
    "            print(f\"\\nüìñ Reading 5 frames...\")\n",
    "            for i in range(5):\n",
    "                ret, frame = video.read()\n",
    "                if ret:\n",
    "                    print(f\"   Frame {i+1}: {frame.shape}\")\n",
    "                else:\n",
    "                    print(f\"   ‚ùå Failed to read frame {i+1}\")\n",
    "                    break\n",
    "        \n",
    "        print(f\"\\n‚úÖ Test passed for {source}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è  Test skipped for {source}: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Exercise 1.2 Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9507fcb0-0751-43ed-b37c-40e898a7f9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXERCISE 1.3: Build Video Output Class\n",
      "================================================================================\n",
      "‚úÖ Class created: VideoOutput\n",
      "\n",
      "üìä Features:\n",
      "   ‚Ä¢ Automatic codec handling\n",
      "   ‚Ä¢ Directory creation\n",
      "   ‚Ä¢ Frame resizing if needed\n",
      "   ‚Ä¢ File size reporting\n",
      "   ‚Ä¢ Context manager support\n",
      "\n",
      "üí° Usage Example:\n",
      "\n",
      "# Create output video\n",
      "with VideoOutput('output.mp4', 1280, 720, 30.0) as writer:\n",
      "    for frame in processed_frames:\n",
      "        writer.write(frame)\n",
      "\n",
      "# File automatically saved and released\n",
      "\n",
      "\n",
      "‚úÖ Exercise 1.3 Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# EXERCISE 1.3: BUILD VIDEO OUTPUT CLASS\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXERCISE 1.3: Build Video Output Class\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\"\"\"\n",
    "üìñ THEORY: Video Output and Export\n",
    "\n",
    "Why Video Output Class?\n",
    "- Save processed videos\n",
    "- Consistent format and quality\n",
    "- Handle codecs properly\n",
    "- Manage file paths\n",
    "- Error handling\n",
    "\n",
    "Key Considerations:\n",
    "1. Codec selection (H.264, H.265, etc.)\n",
    "2. Frame rate matching\n",
    "3. Resolution matching\n",
    "4. Quality vs file size\n",
    "5. Platform compatibility\n",
    "\n",
    "Common Codecs:\n",
    "- 'mp4v': MPEG-4, widely compatible\n",
    "- 'avc1' / 'h264': H.264, best compression\n",
    "- 'XVID': Good quality, older\n",
    "- 'MJPG': Motion JPEG, large files\n",
    "\"\"\"\n",
    "\n",
    "class VideoOutput:\n",
    "    \"\"\"\n",
    "    Video output handler for saving processed videos\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, output_path, width, height, fps, codec='mp4v'):\n",
    "        \"\"\"\n",
    "        Initialize video output\n",
    "        \n",
    "        Args:\n",
    "            output_path: Output file path\n",
    "            width: Frame width\n",
    "            height: Frame height\n",
    "            fps: Frames per second\n",
    "            codec: FourCC codec code\n",
    "        \"\"\"\n",
    "        self.output_path = output_path\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.fps = fps\n",
    "        self.codec = codec\n",
    "        self.writer = None\n",
    "        self.frame_count = 0\n",
    "        \n",
    "        # Create output directory if needed\n",
    "        output_dir = os.path.dirname(output_path)\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            print(f\"üìÅ Created directory: {output_dir}\")\n",
    "        \n",
    "        self._open()\n",
    "    \n",
    "    def _open(self):\n",
    "        \"\"\"Open video writer\"\"\"\n",
    "        # Convert codec string to fourcc\n",
    "        fourcc = cv2.VideoWriter_fourcc(*self.codec)\n",
    "        \n",
    "        # Create writer\n",
    "        self.writer = cv2.VideoWriter(\n",
    "            self.output_path,\n",
    "            fourcc,\n",
    "            self.fps,\n",
    "            (self.width, self.height)\n",
    "        )\n",
    "        \n",
    "        if not self.writer.isOpened():\n",
    "            raise RuntimeError(f\"‚ùå Failed to open video writer: {self.output_path}\")\n",
    "        \n",
    "        print(f\"‚úÖ Video writer opened: {self.output_path}\")\n",
    "        print(f\"   Resolution: {self.width}x{self.height}\")\n",
    "        print(f\"   FPS: {self.fps}\")\n",
    "        print(f\"   Codec: {self.codec}\")\n",
    "    \n",
    "    def write(self, frame):\n",
    "        \"\"\"\n",
    "        Write frame to video\n",
    "        \n",
    "        Args:\n",
    "            frame: Frame to write (numpy array)\n",
    "        \"\"\"\n",
    "        if self.writer is None or not self.writer.isOpened():\n",
    "            raise RuntimeError(\"Video writer not opened\")\n",
    "        \n",
    "        # Ensure frame is correct size\n",
    "        if frame.shape[1] != self.width or frame.shape[0] != self.height:\n",
    "            frame = cv2.resize(frame, (self.width, self.height))\n",
    "        \n",
    "        self.writer.write(frame)\n",
    "        self.frame_count += 1\n",
    "    \n",
    "    def release(self):\n",
    "        \"\"\"Release video writer\"\"\"\n",
    "        if self.writer is not None:\n",
    "            self.writer.release()\n",
    "            \n",
    "            # Check if file was created\n",
    "            if os.path.exists(self.output_path):\n",
    "                file_size = os.path.getsize(self.output_path) / (1024 * 1024)  # MB\n",
    "                print(f\"‚úÖ Video saved: {self.output_path}\")\n",
    "                print(f\"   Frames written: {self.frame_count}\")\n",
    "                print(f\"   File size: {file_size:.2f} MB\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  Video file not created: {self.output_path}\")\n",
    "    \n",
    "    def __enter__(self):\n",
    "        \"\"\"Context manager entry\"\"\"\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Context manager exit\"\"\"\n",
    "        self.release()\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"Destructor\"\"\"\n",
    "        self.release()\n",
    "\n",
    "print(\"‚úÖ Class created: VideoOutput\")\n",
    "print(\"\\nüìä Features:\")\n",
    "print(\"   ‚Ä¢ Automatic codec handling\")\n",
    "print(\"   ‚Ä¢ Directory creation\")\n",
    "print(\"   ‚Ä¢ Frame resizing if needed\")\n",
    "print(\"   ‚Ä¢ File size reporting\")\n",
    "print(\"   ‚Ä¢ Context manager support\")\n",
    "\n",
    "print(\"\\nüí° Usage Example:\")\n",
    "print(\"\"\"\n",
    "# Create output video\n",
    "with VideoOutput('output.mp4', 1280, 720, 30.0) as writer:\n",
    "    for frame in processed_frames:\n",
    "        writer.write(frame)\n",
    "\n",
    "# File automatically saved and released\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n‚úÖ Exercise 1.3 Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "808ab8f6-1b74-45c3-81bf-d088d7a5f267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üé¨ PART 2: MULTI-SOURCE VIDEO PROCESSING\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üé¨ PART 2: MULTI-SOURCE VIDEO PROCESSING\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea79bd5a-daf3-4e4a-b4db-69ade0f3f9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXERCISE 2.1: Build Complete Video Processor\n",
      "================================================================================\n",
      "‚úÖ Class created: VideoProcessor\n",
      "\n",
      "üìä Features:\n",
      "   ‚Ä¢ Complete processing pipeline\n",
      "   ‚Ä¢ Progress tracking with tqdm\n",
      "   ‚Ä¢ Statistics collection\n",
      "   ‚Ä¢ Detection logging (CSV + JSON)\n",
      "   ‚Ä¢ Live display (optional)\n",
      "   ‚Ä¢ Video output (optional)\n",
      "\n",
      "‚úÖ Exercise 2.1 Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# EXERCISE 2.1: BUILD COMPLETE VIDEO PROCESSOR\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXERCISE 2.1: Build Complete Video Processor\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\"\"\"\n",
    "üìñ THEORY: Complete Video Processing Pipeline\n",
    "\n",
    "Components:\n",
    "1. Video Input (reading frames)\n",
    "2. Detection (YOLO)\n",
    "3. Tracking (DeepSORT)\n",
    "4. Visualization (drawing results)\n",
    "5. Video Output (saving results)\n",
    "6. Logging (detection records)\n",
    "\n",
    "Pipeline Flow:\n",
    "Video ‚Üí Read Frame ‚Üí Detect ‚Üí Track ‚Üí Visualize ‚Üí Save ‚Üí Log ‚Üí Repeat\n",
    "\n",
    "Performance Considerations:\n",
    "- Batch processing when possible\n",
    "- Skip frames if needed\n",
    "- Efficient memory usage\n",
    "- Progress tracking\n",
    "- Error recovery\n",
    "\"\"\"\n",
    "\n",
    "class VideoProcessor:\n",
    "    \"\"\"\n",
    "    Complete video processing pipeline\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, tracker, show_display=True, save_video=True, save_logs=True):\n",
    "        \"\"\"\n",
    "        Initialize video processor\n",
    "        \n",
    "        Args:\n",
    "            model: YOLO model\n",
    "            tracker: DeepSORT tracker\n",
    "            show_display: Show live display window\n",
    "            save_video: Save output video\n",
    "            save_logs: Save detection logs\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.tracker = tracker\n",
    "        self.show_display = show_display\n",
    "        self.save_video = save_video\n",
    "        self.save_logs = save_logs\n",
    "        \n",
    "        # Statistics\n",
    "        self.stats = {\n",
    "            'total_frames': 0,\n",
    "            'processed_frames': 0,\n",
    "            'total_detections': 0,\n",
    "            'unique_tracks': set(),\n",
    "            'processing_times': [],\n",
    "            'start_time': None,\n",
    "            'end_time': None\n",
    "        }\n",
    "        \n",
    "        # Detection log\n",
    "        self.detection_log = []\n",
    "    \n",
    "    def process_video(self, input_source, output_path=None, max_frames=None):\n",
    "        \"\"\"\n",
    "        Process video from start to finish\n",
    "        \n",
    "        Args:\n",
    "            input_source: Input video source\n",
    "            output_path: Output video path (if save_video=True)\n",
    "            max_frames: Maximum frames to process (None = all)\n",
    "            \n",
    "        Returns:\n",
    "            dict: Processing statistics\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üé¨ STARTING VIDEO PROCESSING\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        self.stats['start_time'] = time.time()\n",
    "        \n",
    "        # Open input\n",
    "        video_input = VideoInput(input_source)\n",
    "        \n",
    "        # Setup output\n",
    "        video_output = None\n",
    "        if self.save_video and output_path:\n",
    "            video_output = VideoOutput(\n",
    "                output_path,\n",
    "                video_input.width,\n",
    "                video_input.height,\n",
    "                video_input.fps\n",
    "            )\n",
    "        \n",
    "        # Progress bar\n",
    "        total = video_input.total_frames if video_input.total_frames else max_frames\n",
    "        pbar = tqdm(total=total, desc=\"Processing\", unit=\"frame\")\n",
    "        \n",
    "        try:\n",
    "            frame_idx = 0\n",
    "            \n",
    "            while True:\n",
    "                # Check max frames\n",
    "                if max_frames and frame_idx >= max_frames:\n",
    "                    break\n",
    "                \n",
    "                # Read frame\n",
    "                ret, frame = video_input.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                frame_start = time.time()\n",
    "                \n",
    "                # Process frame\n",
    "                processed_frame, detections, tracks = self._process_frame(\n",
    "                    frame, frame_idx, video_input.fps\n",
    "                )\n",
    "                \n",
    "                # Update statistics\n",
    "                self.stats['processed_frames'] += 1\n",
    "                self.stats['total_detections'] += len(detections)\n",
    "                for track in tracks:\n",
    "                    if track.is_confirmed():\n",
    "                        self.stats['unique_tracks'].add(track.track_id)\n",
    "                \n",
    "                # Processing time\n",
    "                frame_time = time.time() - frame_start\n",
    "                self.stats['processing_times'].append(frame_time)\n",
    "                \n",
    "                # Save frame\n",
    "                if video_output:\n",
    "                    video_output.write(processed_frame)\n",
    "                \n",
    "                # Display\n",
    "                if self.show_display:\n",
    "                    cv2.imshow('Video Processing', processed_frame)\n",
    "                    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                        print(\"\\n‚ö†Ô∏è  Processing interrupted by user\")\n",
    "                        break\n",
    "                \n",
    "                # Update progress\n",
    "                pbar.update(1)\n",
    "                frame_idx += 1\n",
    "        \n",
    "        finally:\n",
    "            pbar.close()\n",
    "            video_input.release()\n",
    "            if video_output:\n",
    "                video_output.release()\n",
    "            if self.show_display:\n",
    "                cv2.destroyAllWindows()\n",
    "        \n",
    "        # Final statistics\n",
    "        self.stats['end_time'] = time.time()\n",
    "        self.stats['total_frames'] = frame_idx\n",
    "        \n",
    "        # Save logs\n",
    "        if self.save_logs:\n",
    "            self._save_logs(output_path)\n",
    "        \n",
    "        # Print summary\n",
    "        self._print_summary()\n",
    "        \n",
    "        return self.stats\n",
    "    \n",
    "    def _process_frame(self, frame, frame_idx, fps):\n",
    "        \"\"\"\n",
    "        Process single frame\n",
    "        \n",
    "        Args:\n",
    "            frame: Input frame\n",
    "            frame_idx: Frame index\n",
    "            fps: Video FPS\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (processed_frame, detections, tracks)\n",
    "        \"\"\"\n",
    "        # 1. YOLO Detection\n",
    "        results = self.model.predict(frame, conf=0.5, classes=[0], verbose=False)\n",
    "        detections = results[0].boxes\n",
    "        \n",
    "        # 2. Convert to DeepSORT format\n",
    "        deepsort_input = []\n",
    "        for box in detections:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            conf = float(box.conf[0])\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            deepsort_input.append(([x1, y1, w, h], conf, 'person'))\n",
    "        \n",
    "        # 3. Update tracker\n",
    "        if len(deepsort_input) > 0:\n",
    "            dummy_embeddings = [np.random.rand(128).astype(np.float32) for _ in deepsort_input]\n",
    "            tracks = self.tracker.update_tracks(deepsort_input, embeds=dummy_embeddings, frame=frame)\n",
    "        else:\n",
    "            tracks = []\n",
    "        \n",
    "        # 4. Log detections\n",
    "        timestamp = frame_idx / fps if fps > 0 else frame_idx\n",
    "        for track in tracks:\n",
    "            if track.is_confirmed():\n",
    "                bbox = track.to_ltrb()\n",
    "                self.detection_log.append({\n",
    "                    'frame': frame_idx,\n",
    "                    'timestamp': timestamp,\n",
    "                    'track_id': track.track_id,\n",
    "                    'x1': int(bbox[0]),\n",
    "                    'y1': int(bbox[1]),\n",
    "                    'x2': int(bbox[2]),\n",
    "                    'y2': int(bbox[3])\n",
    "                })\n",
    "        \n",
    "        # 5. Visualize\n",
    "        annotated = self._draw_results(frame.copy(), tracks)\n",
    "        \n",
    "        return annotated, detections, tracks\n",
    "    \n",
    "    def _draw_results(self, frame, tracks):\n",
    "        \"\"\"Draw tracking results on frame\"\"\"\n",
    "        for track in tracks:\n",
    "            if not track.is_confirmed():\n",
    "                continue\n",
    "            \n",
    "            track_id = track.track_id\n",
    "            bbox = track.to_ltrb()\n",
    "            x1, y1, x2, y2 = map(int, bbox)\n",
    "            \n",
    "            # Draw box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            \n",
    "            # Draw ID\n",
    "            label = f'ID: {track_id}'\n",
    "            cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw stats\n",
    "        cv2.putText(frame, f'Tracks: {len([t for t in tracks if t.is_confirmed()])}',\n",
    "                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def _save_logs(self, output_path):\n",
    "        \"\"\"Save detection logs\"\"\"\n",
    "        if not self.detection_log:\n",
    "            return\n",
    "        \n",
    "        # Save as CSV\n",
    "        df = pd.DataFrame(self.detection_log)\n",
    "        log_path = output_path.replace('.mp4', '_detections.csv') if output_path else 'detections.csv'\n",
    "        df.to_csv(log_path, index=False)\n",
    "        print(f\"\\nüìä Saved detection log: {log_path}\")\n",
    "        \n",
    "        # Save as JSON\n",
    "        json_path = log_path.replace('.csv', '.json')\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(self.detection_log, f, indent=2)\n",
    "        print(f\"üìä Saved detection log: {json_path}\")\n",
    "    \n",
    "    def _print_summary(self):\n",
    "        \"\"\"Print processing summary\"\"\"\n",
    "        total_time = self.stats['end_time'] - self.stats['start_time']\n",
    "        avg_time = np.mean(self.stats['processing_times']) if self.stats['processing_times'] else 0\n",
    "        avg_fps = 1 / avg_time if avg_time > 0 else 0\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üìä PROCESSING SUMMARY\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Total frames: {self.stats['total_frames']}\")\n",
    "        print(f\"Processed frames: {self.stats['processed_frames']}\")\n",
    "        print(f\"Total detections: {self.stats['total_detections']}\")\n",
    "        print(f\"Unique tracks: {len(self.stats['unique_tracks'])}\")\n",
    "        print(f\"Total time: {total_time:.1f}s\")\n",
    "        print(f\"Average FPS: {avg_fps:.1f}\")\n",
    "        print(f\"Average time per frame: {avg_time*1000:.1f}ms\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "print(\"‚úÖ Class created: VideoProcessor\")\n",
    "print(\"\\nüìä Features:\")\n",
    "print(\"   ‚Ä¢ Complete processing pipeline\")\n",
    "print(\"   ‚Ä¢ Progress tracking with tqdm\")\n",
    "print(\"   ‚Ä¢ Statistics collection\")\n",
    "print(\"   ‚Ä¢ Detection logging (CSV + JSON)\")\n",
    "print(\"   ‚Ä¢ Live display (optional)\")\n",
    "print(\"   ‚Ä¢ Video output (optional)\")\n",
    "\n",
    "print(\"\\n‚úÖ Exercise 2.1 Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72386516-4922-4504-87d9-a42c34c7877c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXERCISE 2.2: Batch Video Processing\n",
      "================================================================================\n",
      "‚úÖ Class created: BatchProcessor\n",
      "\n",
      "üìä Features:\n",
      "   ‚Ä¢ Directory scanning for videos\n",
      "   ‚Ä¢ Automatic batch processing\n",
      "   ‚Ä¢ Error handling (skip failed files)\n",
      "   ‚Ä¢ Progress tracking per video\n",
      "   ‚Ä¢ Batch summary report\n",
      "   ‚Ä¢ JSON report export\n",
      "\n",
      "üí° Usage Example:\n",
      "\n",
      "# Initialize batch processor\n",
      "batch = BatchProcessor(model, tracker, output_dir='processed_videos')\n",
      "\n",
      "# Find videos in directory\n",
      "videos = batch.find_videos('input_videos')\n",
      "\n",
      "# Process all videos\n",
      "results = batch.process_batch(videos)\n",
      "\n",
      "# Results saved to: processed_videos/\n",
      "\n",
      "\n",
      "‚úÖ Exercise 2.2 Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# EXERCISE 2.2: BATCH VIDEO PROCESSING\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXERCISE 2.2: Batch Video Processing\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\"\"\"\n",
    "üìñ THEORY: Batch Processing Multiple Videos\n",
    "\n",
    "Why Batch Processing?\n",
    "- Process multiple videos automatically\n",
    "- Consistent processing across files\n",
    "- Efficient use of resources\n",
    "- Unattended operation\n",
    "- Scalable to hundreds of videos\n",
    "\n",
    "Key Features:\n",
    "1. Directory scanning (find all videos)\n",
    "2. Queue management (process in order)\n",
    "3. Error handling (skip failed files)\n",
    "4. Progress tracking (overall + per-file)\n",
    "5. Results organization (structured output)\n",
    "6. Summary reporting (what was processed)\n",
    "\n",
    "Use Cases:\n",
    "- Process day's security footage\n",
    "- Analyze archived videos\n",
    "- Batch convert formats\n",
    "- Generate reports for multiple cameras\n",
    "- Post-event analysis\n",
    "\"\"\"\n",
    "\n",
    "class BatchProcessor:\n",
    "    \"\"\"\n",
    "    Batch video processing system\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, tracker, output_dir='output'):\n",
    "        \"\"\"\n",
    "        Initialize batch processor\n",
    "        \n",
    "        Args:\n",
    "            model: YOLO model\n",
    "            tracker: DeepSORT tracker\n",
    "            output_dir: Output directory for results\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.tracker = tracker\n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        # Create output directory\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Results tracking\n",
    "        self.results = []\n",
    "        \n",
    "        print(f\"‚úÖ BatchProcessor initialized\")\n",
    "        print(f\"   Output directory: {output_dir}\")\n",
    "    \n",
    "    def find_videos(self, input_dir, extensions=['.mp4', '.avi', '.mov', '.mkv']):\n",
    "        \"\"\"\n",
    "        Find all video files in directory\n",
    "        \n",
    "        Args:\n",
    "            input_dir: Input directory to scan\n",
    "            extensions: List of video extensions to find\n",
    "            \n",
    "        Returns:\n",
    "            list: List of video file paths\n",
    "        \"\"\"\n",
    "        video_files = []\n",
    "        \n",
    "        if not os.path.exists(input_dir):\n",
    "            print(f\"‚ö†Ô∏è  Directory not found: {input_dir}\")\n",
    "            return video_files\n",
    "        \n",
    "        print(f\"\\nüîç Scanning directory: {input_dir}\")\n",
    "        \n",
    "        for root, dirs, files in os.walk(input_dir):\n",
    "            for file in files:\n",
    "                if any(file.lower().endswith(ext) for ext in extensions):\n",
    "                    video_path = os.path.join(root, file)\n",
    "                    video_files.append(video_path)\n",
    "        \n",
    "        print(f\"‚úÖ Found {len(video_files)} video files\")\n",
    "        for i, vf in enumerate(video_files, 1):\n",
    "            print(f\"   {i}. {os.path.basename(vf)}\")\n",
    "        \n",
    "        return video_files\n",
    "    \n",
    "    def process_batch(self, video_files, save_video=True, save_logs=True):\n",
    "        \"\"\"\n",
    "        Process batch of videos\n",
    "        \n",
    "        Args:\n",
    "            video_files: List of video file paths\n",
    "            save_video: Save output videos\n",
    "            save_logs: Save detection logs\n",
    "            \n",
    "        Returns:\n",
    "            list: Processing results for each video\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"üé¨ BATCH PROCESSING: {len(video_files)} videos\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        overall_start = time.time()\n",
    "        \n",
    "        for idx, video_path in enumerate(video_files, 1):\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"üìπ Processing video {idx}/{len(video_files)}\")\n",
    "            print(f\"   File: {os.path.basename(video_path)}\")\n",
    "            print('='*80)\n",
    "            \n",
    "            try:\n",
    "                # Generate output path\n",
    "                video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "                output_path = os.path.join(self.output_dir, f\"{video_name}_processed.mp4\")\n",
    "                \n",
    "                # Reset tracker for each video\n",
    "                self.tracker = DeepSort(\n",
    "                    max_age=30,\n",
    "                    n_init=3,\n",
    "                    nms_max_overlap=1.0,\n",
    "                    embedder=None\n",
    "                )\n",
    "                \n",
    "                # Create processor\n",
    "                processor = VideoProcessor(\n",
    "                    self.model,\n",
    "                    self.tracker,\n",
    "                    show_display=False,  # No display for batch\n",
    "                    save_video=save_video,\n",
    "                    save_logs=save_logs\n",
    "                )\n",
    "                \n",
    "                # Process video\n",
    "                stats = processor.process_video(video_path, output_path)\n",
    "                \n",
    "                # Store results\n",
    "                result = {\n",
    "                    'video': video_path,\n",
    "                    'output': output_path if save_video else None,\n",
    "                    'status': 'success',\n",
    "                    'stats': stats\n",
    "                }\n",
    "                self.results.append(result)\n",
    "                \n",
    "                print(f\"\\n‚úÖ Video {idx} complete!\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\n‚ùå Error processing video {idx}: {e}\")\n",
    "                result = {\n",
    "                    'video': video_path,\n",
    "                    'output': None,\n",
    "                    'status': 'failed',\n",
    "                    'error': str(e)\n",
    "                }\n",
    "                self.results.append(result)\n",
    "        \n",
    "        # Overall summary\n",
    "        overall_time = time.time() - overall_start\n",
    "        self._print_batch_summary(overall_time)\n",
    "        \n",
    "        # Save batch report\n",
    "        self._save_batch_report()\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def _print_batch_summary(self, total_time):\n",
    "        \"\"\"Print batch processing summary\"\"\"\n",
    "        successful = sum(1 for r in self.results if r['status'] == 'success')\n",
    "        failed = sum(1 for r in self.results if r['status'] == 'failed')\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üìä BATCH PROCESSING SUMMARY\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Total videos: {len(self.results)}\")\n",
    "        print(f\"Successful: {successful}\")\n",
    "        print(f\"Failed: {failed}\")\n",
    "        print(f\"Total time: {total_time:.1f}s ({total_time/60:.1f} minutes)\")\n",
    "        \n",
    "        if successful > 0:\n",
    "            print(f\"\\nüìπ Processed Videos:\")\n",
    "            for i, result in enumerate(self.results, 1):\n",
    "                if result['status'] == 'success':\n",
    "                    stats = result['stats']\n",
    "                    print(f\"   {i}. {os.path.basename(result['video'])}\")\n",
    "                    print(f\"      Frames: {stats['processed_frames']}\")\n",
    "                    print(f\"      Detections: {stats['total_detections']}\")\n",
    "                    print(f\"      Unique tracks: {len(stats['unique_tracks'])}\")\n",
    "        \n",
    "        if failed > 0:\n",
    "            print(f\"\\n‚ùå Failed Videos:\")\n",
    "            for i, result in enumerate(self.results, 1):\n",
    "                if result['status'] == 'failed':\n",
    "                    print(f\"   {i}. {os.path.basename(result['video'])}\")\n",
    "                    print(f\"      Error: {result['error']}\")\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "    \n",
    "    def _save_batch_report(self):\n",
    "        \"\"\"Save batch processing report\"\"\"\n",
    "        report_path = os.path.join(self.output_dir, 'batch_report.json')\n",
    "        \n",
    "        report = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'total_videos': len(self.results),\n",
    "            'successful': sum(1 for r in self.results if r['status'] == 'success'),\n",
    "            'failed': sum(1 for r in self.results if r['status'] == 'failed'),\n",
    "            'results': self.results\n",
    "        }\n",
    "        \n",
    "        with open(report_path, 'w') as f:\n",
    "            json.dump(report, f, indent=2, default=str)\n",
    "        \n",
    "        print(f\"\\nüìÑ Batch report saved: {report_path}\")\n",
    "\n",
    "print(\"‚úÖ Class created: BatchProcessor\")\n",
    "print(\"\\nüìä Features:\")\n",
    "print(\"   ‚Ä¢ Directory scanning for videos\")\n",
    "print(\"   ‚Ä¢ Automatic batch processing\")\n",
    "print(\"   ‚Ä¢ Error handling (skip failed files)\")\n",
    "print(\"   ‚Ä¢ Progress tracking per video\")\n",
    "print(\"   ‚Ä¢ Batch summary report\")\n",
    "print(\"   ‚Ä¢ JSON report export\")\n",
    "\n",
    "print(\"\\nüí° Usage Example:\")\n",
    "print(\"\"\"\n",
    "# Initialize batch processor\n",
    "batch = BatchProcessor(model, tracker, output_dir='processed_videos')\n",
    "\n",
    "# Find videos in directory\n",
    "videos = batch.find_videos('input_videos')\n",
    "\n",
    "# Process all videos\n",
    "results = batch.process_batch(videos)\n",
    "\n",
    "# Results saved to: processed_videos/\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n‚úÖ Exercise 2.2 Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ddeca59-1c0b-4ec3-ab94-b5fc08ced5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üíæ PART 3: EXPORT & DEMONSTRATION\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üíæ PART 3: EXPORT & DEMONSTRATION\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cce333fd-840a-4a51-8f29-6499e72d304b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXERCISE 3.1: Create Demo with Sample Video\n",
      "================================================================================\n",
      "\n",
      "üìπ VIDEO OPTIONS FOR TESTING:\n",
      "\n",
      "Option 1: Use Your Own Video\n",
      "   ‚Ä¢ Any .mp4, .avi, .mov file\n",
      "   ‚Ä¢ Phone recording, downloaded video, etc.\n",
      "   ‚Ä¢ Place in project directory\n",
      "\n",
      "Option 2: Generate Test Video\n",
      "   ‚Ä¢ Run: create_test_video('test.mp4')\n",
      "   ‚Ä¢ Simple synthetic video\n",
      "   ‚Ä¢ Good for testing pipeline\n",
      "\n",
      "Option 3: Download Sample\n",
      "   ‚Ä¢ Search: \"sample video download\"\n",
      "   ‚Ä¢ Free stock footage sites\n",
      "   ‚Ä¢ Short clips (5-30 seconds)\n",
      "\n",
      "For this demo, we'll create a simple test video:\n",
      "\n",
      "\n",
      "üé¨ Creating test video...\n",
      "   Duration: 5s\n",
      "   FPS: 30\n",
      "‚úÖ Test video created: test_video.mp4\n",
      "   Size: 0.23 MB\n",
      "   Frames: 150\n",
      "\n",
      "‚úÖ Exercise 3.1 Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# EXERCISE 3.1: CREATE DEMO WITH SAMPLE VIDEO\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXERCISE 3.1: Create Demo with Sample Video\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\"\"\"\n",
    "üìñ THEORY: Creating Test Videos for Demonstration\n",
    "\n",
    "Options for Test Videos:\n",
    "1. Download sample videos from internet\n",
    "2. Use your own video files\n",
    "3. Generate synthetic test video\n",
    "4. Use video from dataset\n",
    "\n",
    "For today, we'll show how to:\n",
    "- Use any video file you have\n",
    "- Download a sample if needed\n",
    "- Generate a simple test video\n",
    "\"\"\"\n",
    "\n",
    "def create_test_video(output_path='test_video.mp4', duration=10, fps=30):\n",
    "    \"\"\"\n",
    "    Create a simple test video with moving shapes\n",
    "    \n",
    "    Args:\n",
    "        output_path: Output file path\n",
    "        duration: Video duration in seconds\n",
    "        fps: Frames per second\n",
    "    \"\"\"\n",
    "    print(f\"\\nüé¨ Creating test video...\")\n",
    "    print(f\"   Duration: {duration}s\")\n",
    "    print(f\"   FPS: {fps}\")\n",
    "    \n",
    "    width, height = 640, 480\n",
    "    total_frames = duration * fps\n",
    "    \n",
    "    # Create video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    for i in range(total_frames):\n",
    "        # Create frame\n",
    "        frame = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Draw moving circle (simulates person)\n",
    "        x = int(width * (i / total_frames))\n",
    "        y = height // 2\n",
    "        cv2.circle(frame, (x, y), 30, (0, 255, 0), -1)\n",
    "        \n",
    "        # Add frame number\n",
    "        cv2.putText(frame, f'Frame: {i}', (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        \n",
    "        out.write(frame)\n",
    "    \n",
    "    out.release()\n",
    "    \n",
    "    file_size = os.path.getsize(output_path) / (1024 * 1024)\n",
    "    print(f\"‚úÖ Test video created: {output_path}\")\n",
    "    print(f\"   Size: {file_size:.2f} MB\")\n",
    "    print(f\"   Frames: {total_frames}\")\n",
    "\n",
    "print(\"\"\"\n",
    "üìπ VIDEO OPTIONS FOR TESTING:\n",
    "\n",
    "Option 1: Use Your Own Video\n",
    "   ‚Ä¢ Any .mp4, .avi, .mov file\n",
    "   ‚Ä¢ Phone recording, downloaded video, etc.\n",
    "   ‚Ä¢ Place in project directory\n",
    "\n",
    "Option 2: Generate Test Video\n",
    "   ‚Ä¢ Run: create_test_video('test.mp4')\n",
    "   ‚Ä¢ Simple synthetic video\n",
    "   ‚Ä¢ Good for testing pipeline\n",
    "\n",
    "Option 3: Download Sample\n",
    "   ‚Ä¢ Search: \"sample video download\"\n",
    "   ‚Ä¢ Free stock footage sites\n",
    "   ‚Ä¢ Short clips (5-30 seconds)\n",
    "\n",
    "For this demo, we'll create a simple test video:\n",
    "\"\"\")\n",
    "\n",
    "# Create test video\n",
    "create_test_video('test_video.mp4', duration=5, fps=30)\n",
    "\n",
    "print(\"\\n‚úÖ Exercise 3.1 Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea7dd20f-a390-4110-baf8-7725540a3cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXERCISE 3.2: Complete Processing Demo\n",
      "================================================================================\n",
      "\n",
      "üé¨ COMPLETE VIDEO PROCESSING DEMO\n",
      "\n",
      "This demo shows the full pipeline in action!\n",
      "\n",
      "What it does:\n",
      "‚úì Loads YOLO + DeepSORT\n",
      "‚úì Processes video file\n",
      "‚úì Tracks people across frames\n",
      "‚úì Saves annotated video\n",
      "‚úì Exports detection logs (CSV + JSON)\n",
      "‚úì Shows statistics\n",
      "\n",
      "üìù To run:\n",
      "1. Make sure you have a video file\n",
      "2. Update the input_video path below\n",
      "3. Run the cell\n",
      "4. Check 'output/' folder for results!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "DEMO CODE\n",
      "================================================================================\n",
      "\n",
      "Copy this code to run the demo:\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "import cv2\n",
      "import numpy as np\n",
      "from ultralytics import YOLO\n",
      "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
      "\n",
      "# 1. Load models\n",
      "print(\"Loading models...\")\n",
      "model = YOLO('yolov8n.pt')\n",
      "tracker = DeepSort(max_age=30, n_init=3, nms_max_overlap=1.0, embedder=None)\n",
      "\n",
      "print(\"Models loaded!\")\n",
      "\n",
      "# 2. Create processor\n",
      "processor = VideoProcessor(\n",
      "    model=model,\n",
      "    tracker=tracker,\n",
      "    show_display=False,  # Set True to see live\n",
      "    save_video=True,\n",
      "    save_logs=True\n",
      ")\n",
      "\n",
      "# 3. Process video\n",
      "input_video = 'test_video.mp4'  # Change to your video file\n",
      "output_video = 'output/processed_video.mp4'\n",
      "\n",
      "print(f\"\\nProcessing: {input_video}\")\n",
      "stats = processor.process_video(input_video, output_video, max_frames=150)\n",
      "\n",
      "print(\"\\n‚úÖ Demo complete!\")\n",
      "print(f\"\\nüìÅ Check output folder for results:\")\n",
      "print(f\"   ‚Ä¢ {output_video}\")\n",
      "print(f\"   ‚Ä¢ output/processed_video_detections.csv\")\n",
      "print(f\"   ‚Ä¢ output/processed_video_detections.json\")\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "üí° If you have your own video file:\n",
      "   1. Place it in the project folder\n",
      "   2. Change 'test_video.mp4' to your filename\n",
      "   3. Run the code above!\n",
      "\n",
      "‚úÖ Exercise 3.2 Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# EXERCISE 3.2: COMPLETE PROCESSING DEMO\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXERCISE 3.2: Complete Processing Demo\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\"\"\"\n",
    "üìñ THEORY: End-to-End Demo\n",
    "\n",
    "This demonstrates the complete pipeline:\n",
    "1. Load models\n",
    "2. Process video file\n",
    "3. Save annotated video\n",
    "4. Export detection logs\n",
    "5. Display results\n",
    "\n",
    "Note: This will work with ANY video file you have!\n",
    "\"\"\"\n",
    "\n",
    "print(\"\"\"\n",
    "üé¨ COMPLETE VIDEO PROCESSING DEMO\n",
    "\n",
    "This demo shows the full pipeline in action!\n",
    "\n",
    "What it does:\n",
    "‚úì Loads YOLO + DeepSORT\n",
    "‚úì Processes video file\n",
    "‚úì Tracks people across frames\n",
    "‚úì Saves annotated video\n",
    "‚úì Exports detection logs (CSV + JSON)\n",
    "‚úì Shows statistics\n",
    "\n",
    "üìù To run:\n",
    "1. Make sure you have a video file\n",
    "2. Update the input_video path below\n",
    "3. Run the cell\n",
    "4. Check 'output/' folder for results!\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DEMO CODE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "Copy this code to run the demo:\n",
    "\n",
    "-----------------------------------------------------------------------\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# 1. Load models\n",
    "print(\"Loading models...\")\n",
    "model = YOLO('yolov8n.pt')\n",
    "tracker = DeepSort(max_age=30, n_init=3, nms_max_overlap=1.0, embedder=None)\n",
    "\n",
    "print(\"Models loaded!\")\n",
    "\n",
    "# 2. Create processor\n",
    "processor = VideoProcessor(\n",
    "    model=model,\n",
    "    tracker=tracker,\n",
    "    show_display=False,  # Set True to see live\n",
    "    save_video=True,\n",
    "    save_logs=True\n",
    ")\n",
    "\n",
    "# 3. Process video\n",
    "input_video = 'test_video.mp4'  # Change to your video file\n",
    "output_video = 'output/processed_video.mp4'\n",
    "\n",
    "print(f\"\\\\nProcessing: {input_video}\")\n",
    "stats = processor.process_video(input_video, output_video, max_frames=150)\n",
    "\n",
    "print(\"\\\\n‚úÖ Demo complete!\")\n",
    "print(f\"\\\\nüìÅ Check output folder for results:\")\n",
    "print(f\"   ‚Ä¢ {output_video}\")\n",
    "print(f\"   ‚Ä¢ output/processed_video_detections.csv\")\n",
    "print(f\"   ‚Ä¢ output/processed_video_detections.json\")\n",
    "-----------------------------------------------------------------------\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüí° If you have your own video file:\")\n",
    "print(\"   1. Place it in the project folder\")\n",
    "print(\"   2. Change 'test_video.mp4' to your filename\")\n",
    "print(\"   3. Run the code above!\")\n",
    "\n",
    "print(\"\\n‚úÖ Exercise 3.2 Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb3a4aca-a517-4853-a961-6a780546d992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üéØ PART 4: KEY TAKEAWAYS & NEXT STEPS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ PART 4: KEY TAKEAWAYS & NEXT STEPS\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0a02342-5e72-409d-a4f7-4e57ed764b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXERCISE 4.1: Day 25 Summary\n",
      "================================================================================\n",
      "\n",
      "üìö WHAT WE LEARNED TODAY:\n",
      "\n",
      "‚úÖ Video I/O Fundamentals:\n",
      "   ‚Ä¢ Understood different video sources (files, webcam, RTSP)\n",
      "   ‚Ä¢ Learned video file formats and codecs\n",
      "   ‚Ä¢ OpenCV VideoCapture API\n",
      "   ‚Ä¢ Video properties (width, height, FPS, frame count)\n",
      "   ‚Ä¢ Source type detection (auto-detect)\n",
      "\n",
      "‚úÖ Video Input Class:\n",
      "   ‚Ä¢ Built robust VideoInput class\n",
      "   ‚Ä¢ Auto-detect source type\n",
      "   ‚Ä¢ Retry logic for reliability\n",
      "   ‚Ä¢ Context manager support (with statement)\n",
      "   ‚Ä¢ Progress tracking for files\n",
      "   ‚Ä¢ Proper resource cleanup\n",
      "\n",
      "‚úÖ Video Output Class:\n",
      "   ‚Ä¢ Built VideoOutput class for saving\n",
      "   ‚Ä¢ Codec handling (mp4v, H.264)\n",
      "   ‚Ä¢ Frame resizing if needed\n",
      "   ‚Ä¢ Directory creation\n",
      "   ‚Ä¢ File size reporting\n",
      "\n",
      "‚úÖ Complete Video Processor:\n",
      "   ‚Ä¢ Built VideoProcessor class\n",
      "   ‚Ä¢ Full pipeline (input ‚Üí detect ‚Üí track ‚Üí visualize ‚Üí output)\n",
      "   ‚Ä¢ Progress tracking with tqdm\n",
      "   ‚Ä¢ Statistics collection\n",
      "   ‚Ä¢ Detection logging (CSV + JSON)\n",
      "   ‚Ä¢ Live display (optional)\n",
      "   ‚Ä¢ Memory efficient processing\n",
      "\n",
      "‚úÖ Batch Processing:\n",
      "   ‚Ä¢ Built BatchProcessor class\n",
      "   ‚Ä¢ Directory scanning for videos\n",
      "   ‚Ä¢ Automatic batch processing\n",
      "   ‚Ä¢ Error handling (skip failed files)\n",
      "   ‚Ä¢ Progress tracking per video\n",
      "   ‚Ä¢ Batch summary report\n",
      "   ‚Ä¢ JSON report export\n",
      "\n",
      "‚úÖ Testing & Demo:\n",
      "   ‚Ä¢ Created test video generator\n",
      "   ‚Ä¢ Built complete processing demo\n",
      "   ‚Ä¢ Export formats (video, CSV, JSON)\n",
      "   ‚Ä¢ End-to-end pipeline working\n",
      "\n",
      "üìä KEY METRICS TODAY:\n",
      "   ‚Ä¢ Classes created: 4 (VideoInput, VideoOutput, VideoProcessor, BatchProcessor)\n",
      "   ‚Ä¢ Video formats supported: MP4, AVI, MOV, MKV\n",
      "   ‚Ä¢ Export formats: Video (MP4), CSV, JSON\n",
      "   ‚Ä¢ Processing modes: Single video, batch processing\n",
      "   ‚Ä¢ Error handling: Robust with retry logic\n",
      "\n",
      "üí° KEY INSIGHTS:\n",
      "\n",
      "   1. Video I/O requires careful resource management\n",
      "      ‚Üí Always release video captures\n",
      "      ‚Üí Use context managers (with statement)\n",
      "      ‚Üí Handle errors gracefully\n",
      "\n",
      "   2. Different sources need different handling\n",
      "      ‚Üí Files: Can seek, get total frames, process at any speed\n",
      "      ‚Üí Webcam: Real-time only, no seeking, must keep up\n",
      "      ‚Üí RTSP: Network latency, connection drops, buffering\n",
      "\n",
      "   3. Batch processing is powerful\n",
      "      ‚Üí Process multiple videos automatically\n",
      "      ‚Üí Consistent processing across files\n",
      "      ‚Üí Unattended operation\n",
      "      ‚Üí Scalable to hundreds of videos\n",
      "\n",
      "   4. Logging is essential\n",
      "      ‚Üí Detection logs for analysis\n",
      "      ‚Üí Statistics for performance tracking\n",
      "      ‚Üí Reports for auditing\n",
      "      ‚Üí Multiple formats for flexibility\n",
      "\n",
      "   5. Progress tracking improves UX\n",
      "      ‚Üí tqdm provides clean progress bars\n",
      "      ‚Üí Users know processing status\n",
      "      ‚Üí Easier to debug if stuck\n",
      "      ‚Üí Professional appearance\n",
      "\n",
      "   6. Modular design enables reuse\n",
      "      ‚Üí VideoInput works with any source\n",
      "      ‚Üí VideoProcessor works with any video\n",
      "      ‚Üí BatchProcessor scales easily\n",
      "      ‚Üí Components can be used independently\n",
      "\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Exercise 4.1 Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# EXERCISE 4.1: DAY 25 SUMMARY\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXERCISE 4.1: Day 25 Summary\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "üìö WHAT WE LEARNED TODAY:\n",
    "\n",
    "‚úÖ Video I/O Fundamentals:\n",
    "   ‚Ä¢ Understood different video sources (files, webcam, RTSP)\n",
    "   ‚Ä¢ Learned video file formats and codecs\n",
    "   ‚Ä¢ OpenCV VideoCapture API\n",
    "   ‚Ä¢ Video properties (width, height, FPS, frame count)\n",
    "   ‚Ä¢ Source type detection (auto-detect)\n",
    "\n",
    "‚úÖ Video Input Class:\n",
    "   ‚Ä¢ Built robust VideoInput class\n",
    "   ‚Ä¢ Auto-detect source type\n",
    "   ‚Ä¢ Retry logic for reliability\n",
    "   ‚Ä¢ Context manager support (with statement)\n",
    "   ‚Ä¢ Progress tracking for files\n",
    "   ‚Ä¢ Proper resource cleanup\n",
    "\n",
    "‚úÖ Video Output Class:\n",
    "   ‚Ä¢ Built VideoOutput class for saving\n",
    "   ‚Ä¢ Codec handling (mp4v, H.264)\n",
    "   ‚Ä¢ Frame resizing if needed\n",
    "   ‚Ä¢ Directory creation\n",
    "   ‚Ä¢ File size reporting\n",
    "\n",
    "‚úÖ Complete Video Processor:\n",
    "   ‚Ä¢ Built VideoProcessor class\n",
    "   ‚Ä¢ Full pipeline (input ‚Üí detect ‚Üí track ‚Üí visualize ‚Üí output)\n",
    "   ‚Ä¢ Progress tracking with tqdm\n",
    "   ‚Ä¢ Statistics collection\n",
    "   ‚Ä¢ Detection logging (CSV + JSON)\n",
    "   ‚Ä¢ Live display (optional)\n",
    "   ‚Ä¢ Memory efficient processing\n",
    "\n",
    "‚úÖ Batch Processing:\n",
    "   ‚Ä¢ Built BatchProcessor class\n",
    "   ‚Ä¢ Directory scanning for videos\n",
    "   ‚Ä¢ Automatic batch processing\n",
    "   ‚Ä¢ Error handling (skip failed files)\n",
    "   ‚Ä¢ Progress tracking per video\n",
    "   ‚Ä¢ Batch summary report\n",
    "   ‚Ä¢ JSON report export\n",
    "\n",
    "‚úÖ Testing & Demo:\n",
    "   ‚Ä¢ Created test video generator\n",
    "   ‚Ä¢ Built complete processing demo\n",
    "   ‚Ä¢ Export formats (video, CSV, JSON)\n",
    "   ‚Ä¢ End-to-end pipeline working\n",
    "\n",
    "üìä KEY METRICS TODAY:\n",
    "   ‚Ä¢ Classes created: 4 (VideoInput, VideoOutput, VideoProcessor, BatchProcessor)\n",
    "   ‚Ä¢ Video formats supported: MP4, AVI, MOV, MKV\n",
    "   ‚Ä¢ Export formats: Video (MP4), CSV, JSON\n",
    "   ‚Ä¢ Processing modes: Single video, batch processing\n",
    "   ‚Ä¢ Error handling: Robust with retry logic\n",
    "\n",
    "üí° KEY INSIGHTS:\n",
    "\n",
    "   1. Video I/O requires careful resource management\n",
    "      ‚Üí Always release video captures\n",
    "      ‚Üí Use context managers (with statement)\n",
    "      ‚Üí Handle errors gracefully\n",
    "      \n",
    "   2. Different sources need different handling\n",
    "      ‚Üí Files: Can seek, get total frames, process at any speed\n",
    "      ‚Üí Webcam: Real-time only, no seeking, must keep up\n",
    "      ‚Üí RTSP: Network latency, connection drops, buffering\n",
    "      \n",
    "   3. Batch processing is powerful\n",
    "      ‚Üí Process multiple videos automatically\n",
    "      ‚Üí Consistent processing across files\n",
    "      ‚Üí Unattended operation\n",
    "      ‚Üí Scalable to hundreds of videos\n",
    "      \n",
    "   4. Logging is essential\n",
    "      ‚Üí Detection logs for analysis\n",
    "      ‚Üí Statistics for performance tracking\n",
    "      ‚Üí Reports for auditing\n",
    "      ‚Üí Multiple formats for flexibility\n",
    "      \n",
    "   5. Progress tracking improves UX\n",
    "      ‚Üí tqdm provides clean progress bars\n",
    "      ‚Üí Users know processing status\n",
    "      ‚Üí Easier to debug if stuck\n",
    "      ‚Üí Professional appearance\n",
    "      \n",
    "   6. Modular design enables reuse\n",
    "      ‚Üí VideoInput works with any source\n",
    "      ‚Üí VideoProcessor works with any video\n",
    "      ‚Üí BatchProcessor scales easily\n",
    "      ‚Üí Components can be used independently\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n‚úÖ Exercise 4.1 Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf585559-2995-47ce-b534-8bfe69381dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXERCISE 4.2: Tomorrow's Plan\n",
      "================================================================================\n",
      "\n",
      "üéØ DAY 26: TESTING & PERFORMANCE (November 21, 2025)\n",
      "\n",
      "What we'll do:\n",
      "1. Comprehensive testing framework\n",
      "   ‚Ä¢ Unit tests for components\n",
      "   ‚Ä¢ Integration tests for pipeline\n",
      "   ‚Ä¢ Performance benchmarks\n",
      "   ‚Ä¢ Edge case testing\n",
      "\n",
      "2. Test various scenarios\n",
      "   ‚Ä¢ Crowded scenes (many people)\n",
      "   ‚Ä¢ Sparse scenes (few people)\n",
      "   ‚Ä¢ Occlusions (people hidden)\n",
      "   ‚Ä¢ Fast movement\n",
      "   ‚Ä¢ Low lighting\n",
      "   ‚Ä¢ Different resolutions\n",
      "\n",
      "3. Measure tracking accuracy\n",
      "   ‚Ä¢ Track persistence (how long IDs maintained)\n",
      "   ‚Ä¢ ID switches (when same person gets new ID)\n",
      "   ‚Ä¢ False positives (incorrect detections)\n",
      "   ‚Ä¢ False negatives (missed people)\n",
      "   ‚Ä¢ MOTA (Multiple Object Tracking Accuracy)\n",
      "\n",
      "4. Performance optimization\n",
      "   ‚Ä¢ Identify bottlenecks\n",
      "   ‚Ä¢ Optimize slow sections\n",
      "   ‚Ä¢ Memory profiling\n",
      "   ‚Ä¢ GPU vs CPU comparison\n",
      "   ‚Ä¢ Frame skipping strategies\n",
      "\n",
      "5. Create test suite\n",
      "   ‚Ä¢ Automated testing\n",
      "   ‚Ä¢ Regression tests\n",
      "   ‚Ä¢ Performance baselines\n",
      "   ‚Ä¢ Test data organization\n",
      "\n",
      "6. Document findings\n",
      "   ‚Ä¢ What works well\n",
      "   ‚Ä¢ What needs improvement\n",
      "   ‚Ä¢ Performance characteristics\n",
      "   ‚Ä¢ Recommendations\n",
      "\n",
      "Expected outcomes:\n",
      "   ‚Ä¢ Comprehensive test coverage\n",
      "   ‚Ä¢ Performance benchmarks documented\n",
      "   ‚Ä¢ Optimization opportunities identified\n",
      "   ‚Ä¢ System validated for production\n",
      "   ‚Ä¢ Test suite for future changes\n",
      "   ‚Ä¢ Clear understanding of limitations\n",
      "\n",
      "Tech Stack:\n",
      "   ‚Ä¢ pytest (testing framework)\n",
      "   ‚Ä¢ time/timeit (performance measurement)\n",
      "   ‚Ä¢ memory_profiler (memory analysis)\n",
      "   ‚Ä¢ matplotlib (visualization)\n",
      "   ‚Ä¢ pandas (results analysis)\n",
      "\n",
      "Time estimate: 5-6 hours\n",
      "\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Exercise 4.2 Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# EXERCISE 4.2: TOMORROW'S PLAN (DAY 26)\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXERCISE 4.2: Tomorrow's Plan\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "üéØ DAY 26: TESTING & PERFORMANCE (November 21, 2025)\n",
    "\n",
    "What we'll do:\n",
    "1. Comprehensive testing framework\n",
    "   ‚Ä¢ Unit tests for components\n",
    "   ‚Ä¢ Integration tests for pipeline\n",
    "   ‚Ä¢ Performance benchmarks\n",
    "   ‚Ä¢ Edge case testing\n",
    "\n",
    "2. Test various scenarios\n",
    "   ‚Ä¢ Crowded scenes (many people)\n",
    "   ‚Ä¢ Sparse scenes (few people)\n",
    "   ‚Ä¢ Occlusions (people hidden)\n",
    "   ‚Ä¢ Fast movement\n",
    "   ‚Ä¢ Low lighting\n",
    "   ‚Ä¢ Different resolutions\n",
    "\n",
    "3. Measure tracking accuracy\n",
    "   ‚Ä¢ Track persistence (how long IDs maintained)\n",
    "   ‚Ä¢ ID switches (when same person gets new ID)\n",
    "   ‚Ä¢ False positives (incorrect detections)\n",
    "   ‚Ä¢ False negatives (missed people)\n",
    "   ‚Ä¢ MOTA (Multiple Object Tracking Accuracy)\n",
    "\n",
    "4. Performance optimization\n",
    "   ‚Ä¢ Identify bottlenecks\n",
    "   ‚Ä¢ Optimize slow sections\n",
    "   ‚Ä¢ Memory profiling\n",
    "   ‚Ä¢ GPU vs CPU comparison\n",
    "   ‚Ä¢ Frame skipping strategies\n",
    "\n",
    "5. Create test suite\n",
    "   ‚Ä¢ Automated testing\n",
    "   ‚Ä¢ Regression tests\n",
    "   ‚Ä¢ Performance baselines\n",
    "   ‚Ä¢ Test data organization\n",
    "\n",
    "6. Document findings\n",
    "   ‚Ä¢ What works well\n",
    "   ‚Ä¢ What needs improvement\n",
    "   ‚Ä¢ Performance characteristics\n",
    "   ‚Ä¢ Recommendations\n",
    "\n",
    "Expected outcomes:\n",
    "   ‚Ä¢ Comprehensive test coverage\n",
    "   ‚Ä¢ Performance benchmarks documented\n",
    "   ‚Ä¢ Optimization opportunities identified\n",
    "   ‚Ä¢ System validated for production\n",
    "   ‚Ä¢ Test suite for future changes\n",
    "   ‚Ä¢ Clear understanding of limitations\n",
    "\n",
    "Tech Stack:\n",
    "   ‚Ä¢ pytest (testing framework)\n",
    "   ‚Ä¢ time/timeit (performance measurement)\n",
    "   ‚Ä¢ memory_profiler (memory analysis)\n",
    "   ‚Ä¢ matplotlib (visualization)\n",
    "   ‚Ä¢ pandas (results analysis)\n",
    "\n",
    "Time estimate: 5-6 hours\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n‚úÖ Exercise 4.2 Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81891ed9-c7f2-456d-8b5e-e3c8cec9e97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DAY 25 COMPLETE! ‚úÖ\n",
      "================================================================================\n",
      "\n",
      "OBJECTIVES ACHIEVED:\n",
      "   ‚úÖ Built robust video I/O handling (VideoInput, VideoOutput)\n",
      "   ‚úÖ Created complete video processing pipeline\n",
      "   ‚úÖ Implemented multi-source support (files, webcam, RTSP)\n",
      "   ‚úÖ Built batch processing system\n",
      "   ‚úÖ Added detection logging (CSV + JSON export)\n",
      "   ‚úÖ Integrated progress tracking (tqdm)\n",
      "   ‚úÖ Created test video generator\n",
      "   ‚úÖ Built end-to-end demo\n",
      "   ‚úÖ Handled errors gracefully\n",
      "\n",
      "üìä KEY METRICS:\n",
      "   - Classes created: 4 major classes\n",
      "   - Video formats: MP4, AVI, MOV, MKV\n",
      "   - Export formats: Video, CSV, JSON\n",
      "   - Processing modes: Single, batch\n",
      "   - Error handling: Retry logic + graceful failures\n",
      "   - Progress tracking: tqdm integration\n",
      "   - Resource management: Context managers\n",
      "\n",
      "üí° KEY LEARNINGS:\n",
      "   - Video I/O needs careful resource management\n",
      "   - Different sources require different approaches\n",
      "   - Batch processing enables scalability\n",
      "   - Logging essential for analysis\n",
      "   - Progress bars improve user experience\n",
      "   - Modular design enables code reuse\n",
      "   - Error handling critical for production\n",
      "   - Export formats provide flexibility\n",
      "\n",
      "üéØ TOMORROW (DAY 26):\n",
      "   - Build comprehensive test suite\n",
      "   - Test various scenarios (crowded, sparse, occlusions)\n",
      "   - Measure tracking accuracy metrics\n",
      "   - Identify performance bottlenecks\n",
      "   - Create performance benchmarks\n",
      "   - Document findings and recommendations\n",
      "\n",
      "üíæ FILES CREATED TODAY:\n",
      "   - day25_video_pipeline.ipynb (Complete!)\n",
      "   - Classes: VideoInput, VideoOutput, VideoProcessor, BatchProcessor\n",
      "   - Functions: create_test_video()\n",
      "   - Demo code for end-to-end processing\n",
      "   - Test video generator\n",
      "\n",
      "üî• PROGRESS UPDATE:\n",
      "   Week 4: 57% complete (4/7 days)\n",
      "   Overall: 14.9% complete (25/168 days)\n",
      "\n",
      "üöÄ MOMENTUM:\n",
      "   ‚úÖ Week 1: Neural Networks (Complete)\n",
      "   ‚úÖ Week 2: YOLO Detection (Complete - 75.1% mAP)\n",
      "   ‚úÖ Week 3: Medical Classifier (Complete - 94.48%)\n",
      "   ‚úÖ Day 22: Security System Planning (Complete)\n",
      "   ‚úÖ Day 23: DeepSORT Integration (Complete)\n",
      "   ‚úÖ Day 24: Tracking Optimization (Complete)\n",
      "   ‚úÖ Day 25: Video Processing Pipeline (Complete - TODAY!)\n",
      "\n",
      "   Next: Comprehensive testing and performance analysis! üß™\n",
      "\n",
      "üìù NOTES FOR NEXT TIME:\n",
      "   ‚Ä¢ We created test video generator (works without webcam)\n",
      "   ‚Ä¢ All code works with video files\n",
      "   ‚Ä¢ Batch processing ready for multiple videos\n",
      "   ‚Ä¢ Export logs ready for analysis\n",
      "   ‚Ä¢ System ready for testing tomorrow!\n",
      "\n",
      "================================================================================\n",
      "üí° Today I complete video processing pipeline!\n",
      "üìπ Tomorrow we'll test it thoroughly and optimize!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DAY 25 COMPLETE! ‚úÖ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "OBJECTIVES ACHIEVED:\n",
    "   ‚úÖ Built robust video I/O handling (VideoInput, VideoOutput)\n",
    "   ‚úÖ Created complete video processing pipeline\n",
    "   ‚úÖ Implemented multi-source support (files, webcam, RTSP)\n",
    "   ‚úÖ Built batch processing system\n",
    "   ‚úÖ Added detection logging (CSV + JSON export)\n",
    "   ‚úÖ Integrated progress tracking (tqdm)\n",
    "   ‚úÖ Created test video generator\n",
    "   ‚úÖ Built end-to-end demo\n",
    "   ‚úÖ Handled errors gracefully\n",
    "\n",
    "üìä KEY METRICS:\n",
    "   - Classes created: 4 major classes\n",
    "   - Video formats: MP4, AVI, MOV, MKV\n",
    "   - Export formats: Video, CSV, JSON\n",
    "   - Processing modes: Single, batch\n",
    "   - Error handling: Retry logic + graceful failures\n",
    "   - Progress tracking: tqdm integration\n",
    "   - Resource management: Context managers\n",
    "\n",
    "üí° KEY LEARNINGS:\n",
    "   - Video I/O needs careful resource management\n",
    "   - Different sources require different approaches\n",
    "   - Batch processing enables scalability\n",
    "   - Logging essential for analysis\n",
    "   - Progress bars improve user experience\n",
    "   - Modular design enables code reuse\n",
    "   - Error handling critical for production\n",
    "   - Export formats provide flexibility\n",
    "\n",
    "üéØ TOMORROW (DAY 26):\n",
    "   - Build comprehensive test suite\n",
    "   - Test various scenarios (crowded, sparse, occlusions)\n",
    "   - Measure tracking accuracy metrics\n",
    "   - Identify performance bottlenecks\n",
    "   - Create performance benchmarks\n",
    "   - Document findings and recommendations\n",
    "\n",
    "üíæ FILES CREATED TODAY:\n",
    "   - day25_video_pipeline.ipynb (Complete!)\n",
    "   - Classes: VideoInput, VideoOutput, VideoProcessor, BatchProcessor\n",
    "   - Functions: create_test_video()\n",
    "   - Demo code for end-to-end processing\n",
    "   - Test video generator\n",
    "\n",
    "üî• PROGRESS UPDATE:\n",
    "   Week 4: 57% complete (4/7 days)\n",
    "   Overall: 14.9% complete (25/168 days)\n",
    "   \n",
    "üöÄ MOMENTUM:\n",
    "   ‚úÖ Week 1: Neural Networks (Complete)\n",
    "   ‚úÖ Week 2: YOLO Detection (Complete - 75.1% mAP)\n",
    "   ‚úÖ Week 3: Medical Classifier (Complete - 94.48%)\n",
    "   ‚úÖ Day 22: Security System Planning (Complete)\n",
    "   ‚úÖ Day 23: DeepSORT Integration (Complete)\n",
    "   ‚úÖ Day 24: Tracking Optimization (Complete)\n",
    "   ‚úÖ Day 25: Video Processing Pipeline (Complete - TODAY!)\n",
    "   \n",
    "   Next: Comprehensive testing and performance analysis! üß™\n",
    "   \n",
    "üìù NOTES FOR NEXT TIME:\n",
    "   ‚Ä¢ We created test video generator (works without webcam)\n",
    "   ‚Ä¢ All code works with video files\n",
    "   ‚Ä¢ Batch processing ready for multiple videos\n",
    "   ‚Ä¢ Export logs ready for analysis\n",
    "   ‚Ä¢ System ready for testing tomorrow!\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\n",
    "print(\"üí° Today I complete video processing pipeline!\")\n",
    "print(\"üìπ Tomorrow we'll test it thoroughly and optimize!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35bff30-1393-475a-9dcd-92d35bbe3bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
